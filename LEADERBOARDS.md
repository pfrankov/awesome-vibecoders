# Рейтинг популярных AI инструментов и LLM-моделей (09.2025-10.2025)
Данный рейтинг составлен на основе общения участников чата [VibeCoders](https://t.me/+qiEnmSTvH70yYTEy) в период с сентября по 1 октябрь 2025 года. Представляет собой инструменты для кодинга и LLM-модели, которые получили наибольшее внимание и обсуждение в сообществе.


## Рейтинг LLM-моделей

| № | Модель | Рейтинг | Краткое резюме мнений участников |
|---|---|---|---|
| **1** | **GPT-5 / GPT-5-Codex** | ⭐⭐⭐⭐⭐ | **Фаворит для сложных задач и рефакторинга.** Участники считают ее **"game-changer"** и лучшей моделью для кодинга. **GPT-5** хвалят за способность понимать сложные задачи, генерировать меньше лишнего кода и хорошо справляться с дизайном. В режиме **Thinking** она значительно лучше Opus 4.1. В связке с **Kilo Code** и **Codex** называется самой надежной. Несмотря на то, что модель иногда не справляется с задачами с первого раза и может быть медленной, ее способность к рефакторингу и генерации SVG-иконок высоко ценится. |
| **2** | **Gemini (2.5 Pro / 2.0-2.5 flash)** | ⭐⭐⭐⭐ | **Универсальная и мощная модель, особенно для RAG и творческих задач.** Участники отмечают, что **Gemini 2.5 Pro** отлично справляется с большим контекстом, решением олимпиадных задач (лучше GPT, Claude и Grok) и может анализировать аудиофайлы. Модель Gemini хвалят за качественные ответы на русском языке, превосходящие GPT. **Gemini 2.5 flash** выделяется своей высокой скоростью. Однако есть и недостатки: проблемы с редактированием больших файлов и вызовом инструментов (MCP). |
| **3** | **Claude 4 (Sonnet / Opus)** | ⭐⭐⭐⭐ | **Бывший "золотой стандарт", сильный, но с нюансами.** **Claude 4 Sonnet** долгое время считался эталоном для кодинга. Участники отмечают, что он отлично пишет код с нуля и может быть лучше Codex в конкретных задачах. Однако его часто критикуют за "излишнюю проактивность" — добавление ненужных тестов и документации. **Claude 4.5 Sonnet** вызвал смешанные отзывы: с одной стороны, он не справился с задачей и сломал проект, с другой — участники все равно проявляли к нему интерес. В целом, модели Claude считаются одними из лучших. |
| **4** | **GLM (4.5 / 4.6)** | ⭐⭐⭐⭐ | **Прогрессивная китайская модель с большим потенциалом.** **GLM 4.6** удивил участников своей мощью в UI-задачах на Swift, создав рабочий интерактивный компонент по короткому промпту. Отмечается, что для лучших результатов с ним стоит общаться на английском. **GLM 4.5** также показал себя хорошо, особенно в связке с ClaudeCode, и в целом модель хвалят за ее функциональность в китайской версии, не уступающей OpenAI. |
| **5** | **Grok (Code Fast 1 / 4 Fast)** | ⭐⭐⭐ | **Быстрая, бесплатная, но нестабильная.** Модель **Grok Code Fast 1** заметно улучшилась и выполняет задачи по ресерчу быстрее GPT-5-mini, но страдает от зацикливаний. **Grok 4 Fast** доступен бесплатно на OpenRouter и показал себя неплохо в тестах по созданию игры. Однако в целом модели Grok (включая **Sonoma** и **Code Supernova**) считаются слабее аналогов, часто "тупят" и имеют проблемы с вызовом инструментов. |
| **6** | **Qwen (Coder / qwen3)** | ⭐⭐⭐ | **Неплохая бесплатная модель, но требует доработки.** Участники считают **Qwen 3** одной из лучших моделей наравне с Claude 4. **Qwen Coder** хорошо пишет код. Однако новая **Qwen3-Max-Preview** разочаровала: несмотря на высокие заявленные характеристики, участники столкнулись с "мощными косяками". Также отмечается, что Qwen хорош для бэкенда, но плохо справляется с дизайном и фронтендом. |
| **7** | **DeepSeek** | ⭐⭐ | **Очень дешёвая и быстрая, но с серьёзными недостатками.** Главные претензии — частые "галлюцинации", вставка китайских иероглифов и откровенная ложь. Несмотря на это, некоторым участникам она нравится для написания курсовых работ и генерации промптов. |
| **8** | **Sonoma (Sky/Dusk)** | ⭐⭐ | **Слабый дебют предполагаемого Grok.** Новые модели показали себя слабо: **Sky Alpha** выдал нерабочий код, а **Dusk Alpha** не справился с задачей. Участники отметили, что Sonoma Dusk работает лучше на английских промптах, но в целом обе модели "ужасны", сильно ошибаются и имеют проблемы с вызовом инструментов. |

## Рейтинг CLI/IDE инструментов

| № | Инструмент | Рейтинг | Краткое резюме мнений участников |
|---|---|---|---|
| **1** | **Codex (CLI / VS Code Extension)** | ⭐⭐⭐⭐⭐ | **Признанный лидер в сообществе.** Несмотря на периодические сбои и зависания, его хвалят за возможность **запускать задачи в облаке** без нагрузки на ПК. Это делает его **самым выгодным инструментом**, так как функционал включен в подписку ChatGPT Plus. Отмечается, что он **лучше всех решает сложные задачи** и лучше подходит для рефакторинга, чем Sonnet. Локальная версия мощнее облачной.  **Стоит попробовать.** |
| **2** | **Kilo Code** | ⭐⭐⭐⭐ | **Мощный open-source инструмент, но дорогой.** Участники отмечают его **гибкость в настройке агентов и системных промптов**. В связке с GPT-5 показывает себя как надежное решение, иногда превосходя Copilot и Coder. Главный минус — **высокая стоимость** при оплате за токены. Также есть проблемы с изоляцией субагентов и баги, из-за которых теряется контекст.  **Стоит попробовать.** |
| **3** | **GitHub Copilot** | ⭐⭐⭐⭐ | **"Рабочая лошадка" с выгодной подпиской.** Главное преимущество — **выгодная подписка ($10/мес)** с безлимитным доступом к GPT-4.1 и GPT-5-mini. Отмечается его скорость и хорошая интеграция с GitHub. Из минусов — менее удобный интерфейс по сравнению с Cursor и уступает в качестве более продвинутым моделям в сложных задачах. Недавно вышел в **публичное превью для CLI**.  **Стоит попробовать.** |
| **4** | **Claude Code (cc)** | ⭐⭐⭐⭐ | **Хороший инструмент, особенно в связке с альтернативными моделями.** Участники отмечают, что он неплохо работает, а его использование становится **особенно выгодным с китайской моделью GLM 4.5/4.6**. Инструмент имеет проблемы с управлением большим контекстом (открывает файлы по частям) и иногда не вызывает MCP, используя свой встроенный поиск.  **Стоит попробовать.** |
| **5** | **Cursor** | ⭐⭐⭐ | **Потерял популярность из-за ценовой политики.** Ранее был фаворитом благодаря отличному интерфейсу и интеграции с топовыми моделями. Однако изменение ценовой политики, которая стала **непрозрачной и невыгодной**, вызвало массовое недовольство. Кроме того, в тестах он часто генерировал нерабочий код и "сжигал" токены. Тем не менее, некоторые пользователи отмечают его улучшения и продолжают им пользоваться. |
| **6** | **Qoder** | ⭐⭐⭐ | **Перспективный, но нестабильный бесплатный инструмент.** Показывал **лучшие результаты, чем платные аналоги** в некоторых тестах. Его "Quest Mode" способен решать комплексные задачи. Однако были сообщения о его закрытии, хотя позже выяснилось, что он перешел на GPT-5. Пользователи также сталкивались с лагами. **Стоит попробовать.** |
| **7** | **Zed** | ⭐⭐ | **Быстрый, но "сырой" редактор.** Хвалят за скорость и плавность благодаря написанию на Rust. Однако он **очень сырой**: не хватает расширений, автодополнения "тупые". Также были отмечены проблемы с вызовом инструментов у моделей.  **Стоит попробовать.** |
| **8** | **Windsurf** | ⭐ | **Крайне негативные отзывы.** Участники **настоятельно не рекомендуют** его использовать, называя "жестью" и "провалом". Модели в нем плохо редактируют код, ломают файлы и не используют встроенные инструменты. |
| **9** | **Kiro** | ⭐ | **Медленный и не впечатляющий.** Пользователи, получившие доступ, отметили его **крайне медленную работу** . "шошо" считает, что Qoder справляется с задачами лучше. |
| **10** | **Droid** | ⭐ | **"Король кодинга" на бумаге, но не на практике.** Несмотря на заявление о первом месте в бенчмарке Terminal-Bench, при тестировании на стриме инструмент **не показал хороших результатов**. |
